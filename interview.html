<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>AI Voice Interview | Prep</title>
    <link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.3/dist/css/bootstrap.min.css" rel="stylesheet">
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700;800&display=swap" rel="stylesheet">
    <link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.0/css/all.min.css" rel="stylesheet">
    <style>
        :root {
            --primary: #6366f1;
            --primary-dark: #4f46e5;
            --danger: #ef4444;
            --success: #10b981;
            --bg-dark: #0f172a;
            --glass-bg: rgba(255, 255, 255, 0.05);
            --glass-border: rgba(255, 255, 255, 0.1);
        }

        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        body {
            background: linear-gradient(135deg, #0f172a 0%, #1e293b 50%, #334155 100%);
            color: #fff;
            font-family: 'Inter', sans-serif;
            height: 100vh;
            position: relative;
            overflow: hidden;
        }

        /* Animated Background Particles */
        .particles {
            position: fixed;
            top: 0;
            left: 0;
            width: 100%;
            height: 100%;
            z-index: 1;
            pointer-events: none;
        }

        .particle {
            position: absolute;
            background: radial-gradient(circle, rgba(99, 102, 241, 0.6) 0%, transparent 70%);
            border-radius: 50%;
            animation: float 25s infinite linear;
        }

        .particle:nth-child(1) { width: 60px; height: 60px; top: 20%; left: 10%; animation-delay: 0s; }
        .particle:nth-child(2) { width: 40px; height: 40px; top: 60%; right: 20%; animation-delay: -8s; }
        .particle:nth-child(3) { width: 80px; height: 80px; bottom: 30%; left: 30%; animation-delay: -15s; }
        .particle:nth-child(4) { width: 30px; height: 30px; top: 80%; right: 10%; animation-delay: -20s; }

        @keyframes float {
            0%, 100% { transform: translateY(0px) rotate(0deg); opacity: 0.7; }
            33% { transform: translateY(-30px) rotate(120deg); opacity: 1; }
            66% { transform: translateY(-15px) rotate(240deg); opacity: 0.8; }
        }

        .interview-container {
            width: 100%;
            max-width: 700px;
            text-align: center;
            padding: 2rem;
            position: relative;
            z-index: 10;
            height: 100vh;
            display: flex;
            flex-direction: column;
            justify-content: center;
            margin: 0 auto;
        }

        .glass-card {
            background: var(--glass-bg);
            backdrop-filter: blur(25px);
            border-radius: 32px;
            border: 1px solid var(--glass-border);
            padding: 4rem 3rem;
            box-shadow: 
                0 25px 50px -12px rgba(0, 0, 0, 0.5),
                0 0 0 1px rgba(255, 255, 255, 0.05);
            position: relative;
            overflow: hidden;
        }

        .glass-card::before {
            content: '';
            position: absolute;
            top: 0;
            left: 0;
            right: 0;
            height: 1px;
            background: linear-gradient(90deg, transparent, var(--primary), transparent);
            animation: shimmer 3s infinite;
        }

        @keyframes shimmer {
            0% { transform: translateX(-100%); }
            100% { transform: translateX(100%); }
        }

        .header-section {
            margin-bottom: 2rem;
        }

        .step-counter {
            background: linear-gradient(135deg, var(--primary), var(--primary-dark));
            color: white;
            padding: 10px 24px;
            border-radius: 50px;
            font-size: 0.95rem;
            font-weight: 700;
            letter-spacing: 1.5px;
            display: inline-flex;
            align-items: center;
            gap: 0.5rem;
            box-shadow: 0 8px 25px rgba(99, 102, 241, 0.3);
            backdrop-filter: blur(10px);
            margin-bottom: 1.5rem;
        }

        .question-container {
            margin-bottom: 3rem;
            min-height: 120px;
            display: flex;
            align-items: center;
            justify-content: center;
        }

        .question-box {
            font-size: clamp(1.4rem, 3.5vw, 1.8rem);
            font-weight: 700;
            background: linear-gradient(135deg, #f8fafc, #e2e8f0);
            background-clip: text;
            -webkit-background-clip: text;
            -webkit-text-fill-color: transparent;
            line-height: 1.4;
            padding: 1.5rem 2rem;
            border-radius: 20px;
            backdrop-filter: blur(10px);
            box-shadow: 0 15px 35px rgba(0, 0, 0, 0.2);
            position: relative;
        }

        .mic-button {
            width: 120px;
            height: 120px;
            border-radius: 50%;
            background: linear-gradient(135deg, var(--primary), var(--primary-dark));
            border: none;
            color: white;
            font-size: 2.5rem;
            cursor: pointer;
            box-shadow: 0 20px 40px rgba(99, 102, 241, 0.4);
            transition: all 0.3s cubic-bezier(0.175, 0.885, 0.32, 1.275);
        }

        .mic-button.recording {
            background: linear-gradient(135deg, var(--danger), #dc2626);
            animation: pulse-ring 1.5s infinite;
            transform: scale(1.05);
        }

        @keyframes pulse-ring {
            0% { box-shadow: 0 0 0 0 rgba(239, 68, 68, 0.7); }
            70% { box-shadow: 0 0 0 25px rgba(239, 68, 68, 0); }
            100% { box-shadow: 0 0 0 0 rgba(239, 68, 68, 0); }
        }

        .status-text {
            font-size: 1.1rem;
            font-weight: 500;
            opacity: 0.9;
            min-height: 30px;
        }

        .status-speaking { color: var(--primary); }
        .status-listening { color: var(--danger); }

        .progress-fill {
            height: 100%;
            background: linear-gradient(90deg, var(--primary), var(--success));
            border-radius: 10px;
            transition: width 0.8s ease;
            box-shadow: 0 0 20px rgba(99, 102, 241, 0.5);
        }

        .custom-progress {
            height: 10px;
            background: rgba(255,255,255,0.1);
            border-radius: 10px;
            overflow: hidden;
        }

        /* Skip Button specifically for reliability */
        .btn-skip {
            background: rgba(255,255,255,0.1);
            border: 1px solid var(--glass-border);
            color: #94a3b8;
            border-radius: 12px;
            padding: 8px 20px;
            font-size: 0.85rem;
            transition: 0.3s;
            margin-top: 15px;
            cursor: pointer;
        }
        .btn-skip:hover { background: rgba(255,255,255,0.2); color: #fff; }

    </style>
</head>
<body>
    <div class="particles">
        <div class="particle"></div>
        <div class="particle"></div>
        <div class="particle"></div>
        <div class="particle"></div>
    </div>

    <div class="interview-container">
        <div class="glass-card">
            <div class="header-section">
                <div class="step-counter" id="stepCounter">
                    <i class="fas fa-microphone-alt step-icon"></i>
                    QUESTION 1 OF 10
                </div>
            </div>

            <div class="question-container">
                <div class="question-box" id="questionBox">
                    Click the Microphone to start your Interview
                </div>
            </div>

            <div class="mic-section text-center">
                <div class="mic-container">
                    <button class="mic-button" id="micBtn" onclick="toggleMic()">
                        <i class="fas fa-microphone"></i>
                    </button>
                </div>
                <div id="transcriptPreview" style="color:#818cf8; font-style:italic; height:20px; margin-top:10px; font-size:0.9rem;"></div>
            </div>

            <div class="status-section mt-4">
                <div class="status-text" id="statusLabel">Ready to begin.</div>
                <button class="btn-skip" id="skipBtn" onclick="forceNext()" style="display:none;">Manual Next Question</button>
            </div>

            <div class="progress-container">
                <div class="custom-progress">
                    <div id="progressBar" class="progress-fill" style="width: 10%"></div>
                </div>
            </div>
        </div>
    </div>

    

    <script>
        const questions = {{ questions | tojson }};
        let currentIdx = 0;
        let responses = [];
        let isProcessing = false;

        const synth = window.speechSynthesis;
        const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;
        const recognition = new SpeechRecognition();
        
        recognition.continuous = true;
        recognition.lang = 'en-US';
        recognition.interimResults = true;

        const micBtn = document.getElementById('micBtn');
        const statusLabel = document.getElementById('statusLabel');
        const questionBox = document.getElementById('questionBox');
        const stepCounter = document.getElementById('stepCounter');
        const progressBar = document.getElementById('progressBar');
        const transcriptPreview = document.getElementById('transcriptPreview');

        function speakQuestion() {
            if (currentIdx >= questions.length) return;

            isProcessing = false;
            const text = questions[currentIdx];
            questionBox.innerText = text;
            
            const utterance = new SpeechSynthesisUtterance(text);
            utterance.rate = 1.0;

            utterance.onstart = () => {
                statusLabel.innerText = "ðŸ¤– AI is speaking...";
                statusLabel.className = 'status-text status-speaking';
                micBtn.disabled = true;
                document.getElementById('skipBtn').style.display = "none";
            };

            utterance.onend = () => {
                statusLabel.innerText = "ðŸŽ¤ Listening... Say 'Next Question' when finished.";
                statusLabel.className = 'status-text status-ready';
                micBtn.disabled = false;
                document.getElementById('skipBtn').style.display = "inline-block";
                startMic();
            };

            synth.speak(utterance);
        }

        function startMic() {
            try {
                recognition.start();
                micBtn.classList.add('recording');
            } catch(e) { console.log("Mic already active"); }
        }

        function toggleMic() {
            if (currentIdx === 0 && questionBox.innerText.includes("Click")) {
                speakQuestion();
            } else {
                startMic();
            }
        }

        recognition.onresult = (event) => {
            if (isProcessing) return;
            
            let interim = '';
            let finalTranscript = '';
            for (let i = event.resultIndex; i < event.results.length; ++i) {
                if (event.results[i].isFinal) finalTranscript += event.results[i][0].transcript;
                else interim += event.results[i][0].transcript;
            }

            const currentText = (finalTranscript + interim).toLowerCase();
            transcriptPreview.innerText = currentText;

            if (currentText.includes("next question")) {
                forceNext();
            }
        };

        function forceNext() {
            if (isProcessing) return;
            isProcessing = true;

            // CRITICAL: Stop the hardware mic immediately
            recognition.abort();
            micBtn.classList.remove('recording');

            const answerText = transcriptPreview.innerText.replace("next question", "").trim();
            responses.push({
                question: questions[currentIdx],
                answer: answerText || "No verbal response."
            });

            currentIdx++;
            if (currentIdx < questions.length) {
                stepCounter.innerHTML = `<i class="fas fa-microphone-alt step-icon"></i> QUESTION ${currentIdx + 1} OF 10`;
                progressBar.style.width = ((currentIdx + 1) * 10) + "%";
                transcriptPreview.innerText = "";
                
                // Small delay to ensure hardware is released before speaking again
                setTimeout(speakQuestion, 1200);
            } else {
                submitInterview();
            }
        }

        function submitInterview() {
            statusLabel.innerText = "Saving your interview results...";
            fetch('/submit_interview', {
                method: 'POST',
                headers: { 'Content-Type': 'application/json' },
                body: JSON.stringify({ responses: responses })
            })
            .then(res => res.json())
            .then(data => window.location.href = data.redirect)
            .catch(err => console.error("Submit Error:", err));
        }
    </script>
</body>
</html>